{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is better to copy the code here instead of importing to prevent the arg part from running\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import time, random, numpy as np, argparse\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from types import SimpleNamespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "from datasets import SentenceClassificationDataset, SentencePairDataset, \\\n",
    "    load_multitask_data\n",
    "from bert import BertModel\n",
    "from data_loader import MultiTaskBatchSampler,MultiTaskDataset\n",
    "from optimizer import AdamW\n",
    "\n",
    "from evaluation import model_eval_sst, test_model_multitask, model_eval_multitask, compute_loss_weights\n",
    "from tokenizer import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SENTIMENT_CLASSES = 5\n",
    "TQDM_DISABLE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskBERT(nn.Module):\n",
    "    '''\n",
    "    This module should use BERT for 3 tasks:\n",
    "\n",
    "    - Sentiment classification (predict_sentiment)\n",
    "    - Paraphrase detection (predict_paraphrase)\n",
    "    - Semantic Textual Similarity (predict_similarity)\n",
    "    '''\n",
    "    def __init__(self, config):\n",
    "        super(MultitaskBERT, self).__init__()\n",
    "        # You will want to add layers here to perform the downstream tasks.\n",
    "        # Pretrain mode does not require updating bert paramters.\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased', local_files_only=config.local_files_only)\n",
    "        for param in self.bert.parameters():\n",
    "            if config.option == 'pretrain':\n",
    "                param.requires_grad = False\n",
    "            elif config.option == 'finetune':\n",
    "                param.requires_grad = True\n",
    "        ### TODO\n",
    "        self.drop = torch.nn.Dropout(p=0.3)\n",
    "        self.sst_classifier = torch.nn.Linear(self.bert.config.hidden_size, N_SENTIMENT_CLASSES)\n",
    "        self.para_classifier = torch.nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.sts_classifier = torch.nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', local_files_only=config.local_files_only)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask,token_type_ids):\n",
    "        'Takes a batch of sentences and produces embeddings for them.'\n",
    "        # The final BERT embedding is the hidden state of [CLS] token (the first token)\n",
    "        # Here, you can start by just returning the embeddings straight from BERT.\n",
    "        # When thinking of improvements, you can later try modifying this\n",
    "        # (e.g., by adding other layers).\n",
    "        bert_out = self.bert(input_ids, attention_mask,token_type_ids) \n",
    "        dropped = self.drop(bert_out['pooler_output'])\n",
    "        return dropped\n",
    "\n",
    "    def predict(self,input_ids,attention_mask,token_type_ids,task_id):\n",
    "        cls_hidden_state = self.forward(input_ids, attention_mask,token_type_ids)\n",
    "\n",
    "        if task_id==0:\n",
    "            return self.sst_classifier(cls_hidden_state)\n",
    "        elif task_id==1:\n",
    "            return self.para_classifier(cls_hidden_state)\n",
    "        elif task_id==2:\n",
    "            return self.sts_classifier(cls_hidden_state)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid task_id value. Expected 0, 1, or 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, args, config, filepath):\n",
    "    save_info = {\n",
    "        'model': model.state_dict(),\n",
    "        'optim': optimizer.state_dict(),\n",
    "        'args': args,\n",
    "        'model_config': config,\n",
    "        'system_rng': random.getstate(),\n",
    "        'numpy_rng': np.random.get_state(),\n",
    "        'torch_rng': torch.random.get_rng_state(),\n",
    "    }\n",
    "\n",
    "    torch.save(save_info, filepath)\n",
    "    print(f\"save the model to {filepath}\")\n",
    "\n",
    "#Collate function dependent on current task\n",
    "class CustomCollateFn:\n",
    "    def __init__(self, collate_fns):\n",
    "        self.collate_fns = collate_fns\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        task_id,_= batch[0] #This tuple is defined in the MultiTaskDataset class\n",
    "        #This only works if a batch only contains data from one task\n",
    "        collate_fn = self.collate_fns[task_id]\n",
    "        actual_batch = [actual_batch for _, actual_batch in batch]\n",
    "        return collate_fn(actual_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multitask(args):\n",
    "    device = torch.device('cuda') if args.use_gpu else torch.device('cpu')\n",
    "    # Load data\n",
    "    # Create the data and its corresponding datasets and dataloader\n",
    "    sst_train_data, num_labels,para_train_data, sts_train_data = load_multitask_data(args.sst_train,args.para_train,args.sts_train, split ='train')\n",
    "    sst_dev_data, num_labels,para_dev_data, sts_dev_data = load_multitask_data(args.sst_dev,args.para_dev,args.sts_dev, split ='train') #Itis correct to use this slit for dev. The other option is test which does not load the labels\n",
    "    \n",
    "    #Sentiment analysis\n",
    "    sst_train_data = SentenceClassificationDataset(sst_train_data, args)\n",
    "    sst_dev_data = SentenceClassificationDataset(sst_dev_data, args)\n",
    "\n",
    "    sst_dev_dataloader = DataLoader(sst_dev_data, shuffle=False, batch_size=args.batch_size,\n",
    "                                    collate_fn=sst_dev_data.collate_fn)\n",
    "    \n",
    "    #Paraphrasing\n",
    "    paraphrase_train_data = SentencePairDataset(para_train_data, args, isRegression =False)\n",
    "    paraphrase_dev_data = SentencePairDataset(para_dev_data, args, isRegression =False)\n",
    "\n",
    "    paraphrase_dev_dataloader = DataLoader(paraphrase_dev_data, shuffle=False, batch_size=args.batch_size,\n",
    "                                    collate_fn=paraphrase_dev_data.collate_fn)\n",
    "    \n",
    "    #sts\n",
    "    sts_train_data = SentencePairDataset(sts_train_data, args, isRegression =True)\n",
    "    sts_dev_data = SentencePairDataset(sts_dev_data, args, isRegression =True)\n",
    "\n",
    "    sts_dev_dataloader = DataLoader(sts_dev_data, shuffle=False, batch_size=args.batch_size,\n",
    "                                collate_fn=sts_dev_data.collate_fn)\n",
    "    \n",
    "    #MTL data loader\n",
    "    train_datasets = [sst_train_data,paraphrase_train_data, sts_train_data]\n",
    "    #Temporarily initialized here but later in epoch loop to update current epoch and do annealed sampling\n",
    "    mtl_sampler = MultiTaskBatchSampler(        datasets=train_datasets,\n",
    "        current_epoch=1,\n",
    "        total_epochs=args.epochs,\n",
    "        batch_size = args.batch_size,\n",
    "        mix_opt=1,\n",
    "        extra_task_ratio=0,\n",
    "        bin_size=64,\n",
    "        bin_on=False,\n",
    "        bin_grow_ratio=0.5,\n",
    "        sampling='sequential')\n",
    "\n",
    "    multi_task_train_dataset = MultiTaskDataset(train_datasets)\n",
    "\n",
    "    collate_fns = {\n",
    "        0: sst_train_data.collate_fn,\n",
    "        1: paraphrase_train_data.collate_fn,\n",
    "        2: sts_train_data.collate_fn\n",
    "    }\n",
    "\n",
    "    # Creating the custom collate function using the dictionary of collate functions\n",
    "    # Linked to each task id\n",
    "    custom_collate_fn = CustomCollateFn(collate_fns)\n",
    "\n",
    "    multi_task_train_data = DataLoader(\n",
    "    multi_task_train_dataset,\n",
    "    batch_sampler=mtl_sampler,\n",
    "    collate_fn = custom_collate_fn\n",
    "    )\n",
    "\n",
    "    # Init model\n",
    "    config = {'hidden_dropout_prob': args.hidden_dropout_prob,\n",
    "              'num_labels': num_labels,\n",
    "              'hidden_size': 768,\n",
    "              'data_dir': '.',\n",
    "              'option': args.option,\n",
    "              'local_files_only': args.local_files_only}\n",
    "\n",
    "    config = SimpleNamespace(**config)\n",
    "\n",
    "    model = MultitaskBERT(config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    lr = args.lr\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    best_dev_acc_sst = 0\n",
    "    best_dev_acc_paraphrase = 0\n",
    "    best_dev_corr_sts = 0\n",
    "\n",
    "    # Run for the specified number of epochs\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        num_batches = 0\n",
    "        sst_train_loss_list = []\n",
    "        paraphrase_train_loss_list = []\n",
    "        sts_train_loss_list = []\n",
    "        \n",
    "        for batch in tqdm(multi_task_train_data, desc=f'train-{epoch}', disable=TQDM_DISABLE):\n",
    "\n",
    "            #Batch loading, prediction and loss depending on task:\n",
    "            optimizer.zero_grad()\n",
    "            b_task_id, b_ids, b_mask,b_token_type_ids, b_labels = (batch['task_id'],batch['token_ids'],\n",
    "                        batch['attention_mask'],batch['token_type_ids'], batch['labels'])\n",
    "\n",
    "            logits = model.predict(input_ids=b_ids,attention_mask=b_mask,token_type_ids=b_token_type_ids,task_id=b_task_id)\n",
    "            batch_loss = [0]*3\n",
    "            if b_task_id==0: #Sentiment analysis\n",
    "                sst_loss = F.cross_entropy(logits, b_labels.view(-1), reduction='mean')\n",
    "                batch_loss[b_task_id]=sst_loss\n",
    "                sst_train_loss_list.append(sst_loss.item()) #value, not tensor\n",
    "\n",
    "            elif b_task_id==1: #Paraphrasing\n",
    "                bce_loss = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "                paraphrase_loss=bce_loss(logits.view(-1),b_labels.to(torch.float64)) #Change these logits\n",
    "                batch_loss[b_task_id]=paraphrase_loss\n",
    "                paraphrase_train_loss_list.append(paraphrase_loss.item())\n",
    "\n",
    "            elif b_task_id==2: # Text similarity\n",
    "\n",
    "                sigmoid = nn.Sigmoid()\n",
    "                probabilities = sigmoid(logits) #maps logits to range 0 to 1\n",
    "                # Define the MSE loss function\n",
    "                mse_loss = nn.MSELoss(reduction='mean')\n",
    "                b_labels_scaled = (b_labels / 5).float() #Divide between 5 to match range 0 to 1 of logit. Float required due to loss calculation error\n",
    "                sts_loss = mse_loss(probabilities.view(-1), b_labels_scaled)\n",
    "                batch_loss[b_task_id]=sts_loss\n",
    "                sts_train_loss_list.append(sts_loss.item())\n",
    "                        \n",
    "            else:\n",
    "                raise ValueError(\"Invalid b_task_id value. Expected 0, 1, or 2.\")\n",
    "            \n",
    "\n",
    "            losses_list = [sst_train_loss_list,paraphrase_train_loss_list,sts_train_loss_list]\n",
    "            #Compute weighted loss\n",
    "            weights = compute_loss_weights(losses_list)\n",
    "\n",
    "            total_loss = 0\n",
    "            for loss, weight in zip(batch_loss,weights):\n",
    "                total_loss+=loss*weight\n",
    "                \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            #End of training batches\n",
    "\n",
    "        #Start dev evaluation \n",
    "        (dev_paraphrase_accuracy, dev_para_y_pred, dev_para_sent_ids,\n",
    "         dev_sentiment_accuracy,dev_sst_y_pred, dev_sst_sent_ids,\n",
    "           dev_sts_corr, dev_sts_y_pred, dev__sent_ids) = model_eval_multitask(sst_dev_dataloader,\n",
    "                                                                      paraphrase_dev_dataloader,sts_dev_dataloader,model, device  )\n",
    "        \n",
    "        #We have to weight or average the three sores to save the best model.\n",
    "        # In the diven code only sst is used\n",
    "\n",
    "\n",
    "        if dev_sentiment_accuracy > best_dev_acc_sst and dev_paraphrase_accuracy >best_dev_acc_paraphrase and dev_sts_corr>best_dev_corr_sts:\n",
    "            best_dev_acc_sst = dev_sentiment_accuracy\n",
    "            best_dev_acc_paraphrase = dev_paraphrase_accuracy\n",
    "            best_dev_corr_sts = dev_sts_corr\n",
    "            save_model(model, optimizer, args, config, args.filepath)\n",
    "\n",
    "        print(f\"Epoch {epoch}: train loss :: {train_loss :.3f}, dev sentiment acc :: {dev_paraphrase_accuracy :.3f}, dev sentiment acc :: {dev_paraphrase_accuracy :.3f}, dev sts corr :: {best_dev_corr_sts :.3f}\")\n",
    "        #Add train metrics to this print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tempArgs():\n",
    "    def __init__(self,):\n",
    "        self.local_files_only=True\n",
    "        self.use_gpu = False\n",
    "        self.sst_train=\"data/ids-sst-train.csv\"\n",
    "        self.sst_dev=\"data/ids-sst-dev.csv\"\n",
    "        self.sst_test=\"data/ids-sst-test-student.csv\"\n",
    "        self.para_train=\"data/quora-train.csv\"\n",
    "        self.para_dev=\"data/quora-dev.csv\"\n",
    "        self.para_test=\"data/quora-test-student.csv\"\n",
    "        self.sts_train=\"data/sts-train.csv\"\n",
    "        self.sts_dev=\"data/sts-dev.csv\"\n",
    "        self.sts_test=\"data/sts-test-student.csv\"\n",
    "        self.batch_size = 32\n",
    "        self.hidden_dropout_prob = 0.3\n",
    "        self.option=\"pretrain\"\n",
    "        self.lr = 1e-3\n",
    "        self.epochs = 10\n",
    "tempargs = tempArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8544 train examples from data/ids-sst-train.csv\n",
      "Loaded 141498 train examples from data/quora-train.csv\n",
      "Loaded 6040 train examples from data/sts-train.csv\n",
      "Loaded 1101 train examples from data/ids-sst-dev.csv\n",
      "Loaded 20212 train examples from data/quora-dev.csv\n",
      "Loaded 863 train examples from data/sts-dev.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'token_ids_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_multitask(tempargs)\n",
      "Cell \u001b[1;32mIn[55], line 143\u001b[0m, in \u001b[0;36mtrain_multitask\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    136\u001b[0m     num_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    138\u001b[0m     \u001b[39m#End of training batches\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[39m#Start dev evaluation \u001b[39;00m\n\u001b[0;32m    141\u001b[0m (dev_paraphrase_accuracy, dev_para_y_pred, dev_para_sent_ids,\n\u001b[0;32m    142\u001b[0m  dev_sentiment_accuracy,dev_sst_y_pred, dev_sst_sent_ids,\n\u001b[1;32m--> 143\u001b[0m    dev_sts_corr, dev_sts_y_pred, dev__sent_ids) \u001b[39m=\u001b[39m model_eval_multitask(sst_dev_dataloader,\n\u001b[0;32m    144\u001b[0m                                                               paraphrase_dev_dataloader,sts_dev_dataloader,model, device  )\n\u001b[0;32m    146\u001b[0m \u001b[39m#We have to weight or average the three sores to save the best model.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39m# In the diven code only sst is used\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39mif\u001b[39;00m dev_sentiment_accuracy \u001b[39m>\u001b[39m best_dev_acc_sst \u001b[39mand\u001b[39;00m dev_paraphrase_accuracy \u001b[39m>\u001b[39mbest_dev_acc_paraphrase \u001b[39mand\u001b[39;00m dev_sts_corr\u001b[39m>\u001b[39mbest_dev_corr_sts:\n",
      "File \u001b[1;32mc:\\Users\\sago\\Documents\\GitHub\\word-alliance\\evaluation.py:76\u001b[0m, in \u001b[0;36mmodel_eval_multitask\u001b[1;34m(sentiment_dataloader, paraphrase_dataloader, sts_dataloader, model, device)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m# Evaluate paraphrase detection.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mfor\u001b[39;00m step, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(paraphrase_dataloader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39meval\u001b[39m\u001b[39m'\u001b[39m, disable\u001b[39m=\u001b[39mTQDM_DISABLE)):\n\u001b[0;32m     74\u001b[0m     (b_ids1, b_mask1,\n\u001b[0;32m     75\u001b[0m      b_ids2, b_mask2,\n\u001b[1;32m---> 76\u001b[0m      b_labels, b_sent_ids) \u001b[39m=\u001b[39m (batch[\u001b[39m'\u001b[39;49m\u001b[39mtoken_ids_1\u001b[39;49m\u001b[39m'\u001b[39;49m], batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask_1\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     77\u001b[0m                   batch[\u001b[39m'\u001b[39m\u001b[39mtoken_ids_2\u001b[39m\u001b[39m'\u001b[39m], batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask_2\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     78\u001b[0m                   batch[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m], batch[\u001b[39m'\u001b[39m\u001b[39msent_ids\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     80\u001b[0m     b_ids1 \u001b[39m=\u001b[39m b_ids1\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     81\u001b[0m     b_mask1 \u001b[39m=\u001b[39m b_mask1\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'token_ids_1'"
     ]
    }
   ],
   "source": [
    "train_multitask(tempargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
