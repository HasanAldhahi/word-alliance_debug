{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a56b268-810d-49ab-87d5-c5090cf7cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_multitask_data\n",
    "from bert import BertSelfAttention\n",
    "from bert import BertModel\n",
    "from config import PretrainedConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f30c7b-5bae-473c-adc1-d1d7b9b99c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8544 train examples from data/ids-sst-train.csv\n",
      "Loaded 141498 train examples from data/quora-train.csv\n",
      "Loaded 6040 train examples from data/sts-train.csv\n"
     ]
    }
   ],
   "source": [
    "sentiment_data, num_labels, paraphrased_data, similarity_data = load_multitask_data(\"data/ids-sst-train.csv\", \"data/quora-train.csv\", \n",
    "                    \"data/sts-train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c90542-93ff-4aad-8203-c4c88d228740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"the rock is destined to be the 21st century 's new `` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\",\n",
       " 3,\n",
       " '32a4f146782cbde1b7fa65799')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0efc78-e290-42cc-855f-f25a76ee90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BertConfig(PretrainedConfig):\n",
    "  model_type = \"bert\"\n",
    "\n",
    "  def __init__(\n",
    "    self,\n",
    "    vocab_size=30522,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    initializer_range=0.02,\n",
    "    layer_norm_eps=1e-12,\n",
    "    pad_token_id=0,\n",
    "    gradient_checkpointing=False,\n",
    "    position_embedding_type=\"absolute\",\n",
    "    use_cache=True,\n",
    "    name_or_path = \"checkpoint\",\n",
    "    **kwargs\n",
    "  ):\n",
    "    super().__init__(pad_token_id=pad_token_id, **kwargs)\n",
    "\n",
    "    self.vocab_size = vocab_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_hidden_layers = num_hidden_layers\n",
    "    self.num_attention_heads = num_attention_heads\n",
    "    self.hidden_act = hidden_act\n",
    "    self.intermediate_size = intermediate_size\n",
    "    self.hidden_dropout_prob = hidden_dropout_prob\n",
    "    self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "    self.max_position_embeddings = max_position_embeddings\n",
    "    self.type_vocab_size = type_vocab_size\n",
    "    self.initializer_range = initializer_range\n",
    "    self.layer_norm_eps = layer_norm_eps\n",
    "    self.gradient_checkpointing = gradient_checkpointing\n",
    "    self.position_embedding_type = position_embedding_type\n",
    "    self.use_cache = use_cache\n",
    "    self.name_or_path = name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b59d73a-4959-42c0-a543-098055647857",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig()\n",
    "bert = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6feb8982-88f4-4532-a12d-dec1dbc5334d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertSelfAttention(\n",
       "  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.bert_layers[0].self_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4dec1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we should try to tokenize and find the vector representation of the input sentences. \n",
    "# Key,value and query are obtained from the transform method of BertSelfAttention\n",
    "# These 3 values are 3 linear layers of the same size equal to the hidden size.\n",
    "# We should be able to test the attention method with the initialized values\n",
    "# Where do we get the attention mask from? Where do we process the data?\n",
    "# It seems that we get the attention masks from the datasets script and the tokenizers produced the attention mask!\n",
    "# So we could instantiate class SentencePairDataset(Dataset): for instance to get the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55a2dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import SentencePairDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d6c3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SentencePairDataset(paraphrased_data,args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e495d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data = data.collate_fn(paraphrased_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7198bc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([141498, 118])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data['attention_mask_1'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c9bc1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([141498, 118])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data['token_ids_1'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69c73919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token_ids_1', 'token_type_ids_1', 'attention_mask_1', 'token_ids_2', 'token_type_ids_2', 'attention_mask_2', 'labels', 'sent_ids'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c79d89e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (141498x118 and 768x768)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bert\u001b[39m.\u001b[39;49mbert_layers[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mself_attention\u001b[39m.\u001b[39;49mforward(hidden_states \u001b[39m=\u001b[39;49m padded_data[\u001b[39m'\u001b[39;49m\u001b[39mtoken_ids_1\u001b[39;49m\u001b[39m'\u001b[39;49m],attention_mask \u001b[39m=\u001b[39;49m padded_data[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask_1\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\sago\\Documents\\GitHub\\word-alliance\\minbert-default-final-project-forked\\bert.py:65\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39mhidden_states: [bs, seq_len, hidden_state]\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mattention_mask: [bs, 1, 1, seq_len]\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39moutput: [bs, seq_len, hidden_state]\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39m# first, we have to generate the key, value, query for each token for multi-head attention w/ transform (more details inside the function)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m# of *_layers are of [bs, num_attention_heads, seq_len, attention_head_size]\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(hidden_states, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey)\n\u001b[0;32m     66\u001b[0m value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue)\n\u001b[0;32m     67\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery)\n",
      "File \u001b[1;32mc:\\Users\\sago\\Documents\\GitHub\\word-alliance\\minbert-default-final-project-forked\\bert.py:29\u001b[0m, in \u001b[0;36mBertSelfAttention.transform\u001b[1;34m(self, x, linear_layer)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, x, linear_layer):\n\u001b[0;32m     27\u001b[0m   \u001b[39m# the corresponding linear_layer of k, v, q are used to project the hidden_state (x)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m   bs, seq_len \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n\u001b[1;32m---> 29\u001b[0m   proj \u001b[39m=\u001b[39m linear_layer(x)\n\u001b[0;32m     30\u001b[0m   \u001b[39m# next, we need to produce multiple heads for the proj \u001b[39;00m\n\u001b[0;32m     31\u001b[0m   \u001b[39m# this is done by spliting the hidden state to self.num_attention_heads, each of size self.attention_head_size\u001b[39;00m\n\u001b[0;32m     32\u001b[0m   proj \u001b[39m=\u001b[39m proj\u001b[39m.\u001b[39mview(bs, seq_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_head_size)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dnlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dnlp\\lib\\site-packages\\torch\\nn\\modules\\linear.py:94\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 94\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dnlp\\lib\\site-packages\\torch\\nn\\functional.py:1753\u001b[0m, in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight):\n\u001b[0;32m   1752\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[1;32m-> 1753\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (141498x118 and 768x768)"
     ]
    }
   ],
   "source": [
    "bert.bert_layers[0].self_attention.forward(hidden_states = padded_data['token_ids_1'],attention_mask = padded_data['attention_mask_1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
