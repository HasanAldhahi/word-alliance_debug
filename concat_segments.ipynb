{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_multitask_data, SentenceClassificationDataset, SentencePairDataset\n",
    "from config import PretrainedConfig\n",
    "import torch\n",
    "from base_bert import BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8544 train examples from data/ids-sst-train.csv\n",
      "Loaded 141498 train examples from data/quora-train.csv\n",
      "Loaded 6040 train examples from data/sts-train.csv\n"
     ]
    }
   ],
   "source": [
    "sentiment_data, num_labels, paraphrase_data, similarity_data = load_multitask_data(sentiment_filename='data/ids-sst-train.csv',paraphrase_filename='data/quora-train.csv',similarity_filename='data/sts-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tempArgs():\n",
    "    def __init__(self,):\n",
    "        self.local_files_only=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempargs = tempArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_train_data = SentencePairDataset(paraphrase_data,tempargs,isRegression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_para_data = para_train_data.collate_fn(para_train_data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 600])\n",
      "Concatenated tensor: tensor([[1., 2., 3.,  ..., 0., 0., 0.],\n",
      "        [7., 8., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sep_token_id = para_train_data.tokenizer.vocab['[SEP]']\n",
    "# Determine the length needed for padding\n",
    "max_length = 600\n",
    "def concatenate_with_padding_and_mask(tensor1, tensor2,mask1,mask2):\n",
    "    concatenated_tensors = []\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(len(tensor1)):\n",
    "        non_zero_indices1 = torch.nonzero(mask1[i], as_tuple=False).squeeze()\n",
    "        non_zero_indices2 = torch.nonzero(mask2[i], as_tuple=False).squeeze()\n",
    "        \n",
    "        # Get the maximum non-zero index for each tensor separately\n",
    "        max_index1 = torch.max(non_zero_indices1).item() + 1\n",
    "        max_index2 = torch.max(non_zero_indices2).item() + 1\n",
    "\n",
    "        # Concatenate the tensors and update attention masks\n",
    "        # the second tensor concatenatesfrom position 1 because the separator \n",
    "        concatenated_tensor = torch.cat((tensor1[i][:max_index1], tensor2[i][1:max_index2]), dim=0)\n",
    "\n",
    "        # Pad the concatenated tensor and mask to the maximum length\n",
    "        padding_length = max_length - len(concatenated_tensor)\n",
    "        padding = torch.zeros(padding_length)\n",
    "\n",
    "        concatenated_tensor = torch.cat((concatenated_tensor, padding), dim=0)\n",
    "\n",
    "        concatenated_tensors.append(concatenated_tensor)\n",
    "\n",
    "    return torch.stack(concatenated_tensors)\n",
    "\n",
    "# Example usage with batch_size=2 and sequence_length=6\n",
    "tensor1 = torch.tensor([[1, 2, 3, 0, 0, 0],\n",
    "                        [7, 8, 0, 0, 0, 0]])\n",
    "tensor2 = torch.tensor([[0, 0, 0, 4, 5, 6],\n",
    "                        [9, 0, 0, 0, 0, 0]])\n",
    "\n",
    "\n",
    "mask1 = torch.tensor([[1, 1, 1, 0, 0, 0],\n",
    "                      [1, 1, 0, 0, 0, 0]])\n",
    "mask2 = torch.tensor([[0, 0, 0, 1, 1, 1],\n",
    "                      [1, 0, 0, 0, 0, 0]])\n",
    "\n",
    "\n",
    "result= concatenate_with_padding_and_mask(tensor1, tensor2, mask1, mask2)\n",
    "print(result.shape)\n",
    "print(\"Concatenated tensor:\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenation = concatenate_with_padding_and_mask(batched_para_data['token_ids_1'],batched_para_data['token_ids_2'],batched_para_data['attention_mask_1'],batched_para_data['attention_mask_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101.,  2129.,  2064.,  1045.,  3040.,  2870.,  1999., 10988.,  1029.,\n",
       "          102.,  2129.,  2064.,  1045.,  3040., 10988.,  2005.,  1996.,  4937.,\n",
       "         1011.,  2403.,  1029.,   102.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_occurrence(tensor):\n",
    "    # Find the index of the first occurrence of value 102 (SEP token) for each row\n",
    "    first_occurrence_indices = []\n",
    "    for index, row in enumerate(tensor):\n",
    "        index = torch.nonzero(row == 102, as_tuple=False)\n",
    "        if len(index) > 0:\n",
    "            first_occurrence_indices.append(index[0, 0].item())\n",
    "        else:\n",
    "            print(index)\n",
    "            first_occurrence_indices.append(None)\n",
    "    return first_occurrence_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask(tensor):\n",
    "    # Get the first occurrence of 102 for each row in the tensor\n",
    "    first_occurrence_indices = find_first_occurrence(tensor)\n",
    "\n",
    "    # Create an attention mask tensor filled with ones\n",
    "    attention_mask = torch.ones_like(tensor)\n",
    "\n",
    "    # Set the values before the first occurrence of 102 to zeros\n",
    "    for i, idx in enumerate(first_occurrence_indices):\n",
    "        if idx is not None:\n",
    "            attention_mask[i, :idx + 1] = 0\n",
    "        else:\n",
    "            attention_mask[i] = 0\n",
    "\n",
    "    return attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_attention_mask = create_attention_mask(concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([  101.,  2129.,  2064.,  1045.,  3040.,  2870.,  1999., 10988.,  1029.,\n",
      "          102.,  2129.,  2064.,  1045.,  3040., 10988.,  2005.,  1996.,  4937.,\n",
      "         1011.,  2403.,  1029.,   102.,     0.,     0.,     0.])\n"
     ]
    }
   ],
   "source": [
    "print(new_attention_mask[0][:25])\n",
    "print(concatenation[0][:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from datasets import load_multitask_data\n",
    "import bert\n",
    "from config import PretrainedConfig\n",
    "import torch\n",
    "from datasets import SentencePairDataset\n",
    "from tokenizer import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(BertPreTrainedModel):\n",
    "  \"\"\"\n",
    "  the bert model returns the final embeddings for each token in a sentence\n",
    "  it consists\n",
    "  1. embedding (used in self.embed)\n",
    "  2. a stack of n bert layers (used in self.encode)\n",
    "  3. a linear transformation layer for [CLS] token (used in self.forward, as given)\n",
    "  \"\"\"\n",
    "  def __init__(self, config):\n",
    "    super().__init__(config)\n",
    "    self.config = config\n",
    "\n",
    "    # embedding\n",
    "    self.word_embedding = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
    "    self.pos_embedding = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "    self.tk_type_embedding = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "    self.embed_layer_norm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "    self.embed_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "    # position_ids (1, len position emb) is a constant, register to buffer\n",
    "    position_ids = torch.arange(config.max_position_embeddings).unsqueeze(0)\n",
    "    self.register_buffer('position_ids', position_ids)\n",
    "\n",
    "    # bert encoder\n",
    "    self.bert_layers = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    # for [CLS] token\n",
    "    self.pooler_dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "    self.pooler_af = nn.Tanh()\n",
    "\n",
    "    self.init_weights()\n",
    "\n",
    "  def embed(self, input_ids):\n",
    "    input_shape = input_ids.size()\n",
    "    seq_length = input_shape[1]\n",
    "\n",
    "    # Get word embedding from self.word_embedding into input_embeds.\n",
    "    inputs_embeds = self.word_embedding(input_ids)\n",
    "\n",
    "    # Get position index and position embedding from self.pos_embedding into pos_embeds.\n",
    "    pos_ids = self.position_ids[:, :seq_length] #subsets a list of positions 0:512 to 0:seq_length. \n",
    "\n",
    "    pos_embeds = self.pos_embedding(pos_ids)\n",
    "\n",
    "\n",
    "    # Get token type ids, since we are not consider token type, just a placeholder.\n",
    "    #tk_type_ids = torch.zeros(input_shape, dtype=torch.long, device=input_ids.device)\n",
    "    tk_type_ids = concatenate_with_padding_and_mask(inputs_embeds['token_ids_1'],inputs_embeds['token_ids_2'],inputs_embeds['attention_mask_1'],inputs_embeds['attention_mask_2'])\n",
    "    tk_type_ids = create_attention_mask(tk_type_ids)\n",
    "    tk_type_embeds = self.tk_type_embedding(tk_type_ids)\n",
    "\n",
    "    # Add three embeddings together; then apply embed_layer_norm and dropout and return.\n",
    "    hidden_states = inputs_embeds+pos_embeds+tk_type_embeds\n",
    "    hidden_states = self.embed_layer_norm(hidden_states)\n",
    "    hidden_states = self.embed_dropout(hidden_states)\n",
    "\n",
    "    return hidden_states\n",
    "\n",
    "\n",
    "  def encode(self, hidden_states, attention_mask):\n",
    "    \"\"\"\n",
    "    hidden_states: the output from the embedding layer [batch_size, seq_len, hidden_size]\n",
    "    attention_mask: [batch_size, seq_len]\n",
    "    \"\"\"\n",
    "    # get the extended attention mask for self attention\n",
    "    # returns extended_attention_mask of [batch_size, 1, 1, seq_len]\n",
    "    # non-padding tokens with 0 and padding tokens with a large negative number \n",
    "    extended_attention_mask: torch.Tensor = get_extended_attention_mask(attention_mask, self.dtype)\n",
    "\n",
    "    # pass the hidden states through the encoder layers\n",
    "    for i, layer_module in enumerate(self.bert_layers):\n",
    "      # feed the encoding from the last bert_layer to the next\n",
    "      hidden_states = layer_module(hidden_states, extended_attention_mask)\n",
    "\n",
    "    return hidden_states\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    \"\"\"\n",
    "    input_ids: [batch_size, seq_len], seq_len is the max length of the batch\n",
    "    attention_mask: same size as input_ids, 1 represents non-padding tokens, 0 represents padding tokens\n",
    "    \"\"\"\n",
    "    # get the embedding for each input token\n",
    "    embedding_output = self.embed(input_ids=input_ids)\n",
    "\n",
    "    # feed to a transformer (a stack of BertLayers)\n",
    "    sequence_output = self.encode(embedding_output, attention_mask=attention_mask)\n",
    "\n",
    "    # get cls token hidden state\n",
    "    first_tk = sequence_output[:, 0]\n",
    "    first_tk = self.pooler_dense(first_tk)\n",
    "    first_tk = self.pooler_af(first_tk)\n",
    "\n",
    "    return {'last_hidden_state': sequence_output, 'pooler_output': first_tk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 \n",
    "para_train_data = SentencePairDataset(paraphrase_data,tempargs,isRegression=False)\n",
    "# 2 \n",
    "batched_para_data = para_train_data.collate_fn(para_train_data.dataset)\n",
    "# 3 \n",
    "concatenation = concatenate_with_padding_and_mask(batched_para_data['token_ids_1'],batched_para_data['token_ids_2'],batched_para_data['attention_mask_1'],batched_para_data['attention_mask_2'])\n",
    "# 4 \n",
    "new_attention_mask = create_attention_mask(concatenation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.1205,  0.3894,  1.2717,  ...,  0.4214,  0.5916,  0.3167],\n",
      "         [-0.2933, -0.8539, -0.4161,  ...,  0.5703,  1.6586, -0.0000],\n",
      "         [-0.0000,  0.0000,  1.0828,  ...,  0.8246,  2.2696, -0.3733],\n",
      "         [-0.4785,  0.1608,  1.5891,  ...,  0.0158, -0.0000,  0.0948]],\n",
      "\n",
      "        [[-2.1205,  0.3894,  1.2717,  ...,  0.4214,  0.5916,  0.0000],\n",
      "         [ 1.8705,  1.0076,  0.0000,  ..., -0.4253,  0.4604,  0.8472],\n",
      "         [-0.7460,  1.3952,  0.8652,  ..., -0.4192, -0.4473, -0.7033],\n",
      "         [-0.4785,  0.1608,  1.5891,  ...,  0.0158, -0.0089,  0.0948]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "        self.position_embedding = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.segment_embedding = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "        \n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None):\n",
    "        token_embeddings = self.token_embedding(input_ids)\n",
    "        position_ids = torch.arange(input_ids.size(1), dtype=torch.long, device=input_ids.device)\n",
    "        position_embeddings = self.position_embedding(position_ids.unsqueeze(0))\n",
    "        \n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        \n",
    "        if token_type_ids is not None:\n",
    "            segment_embeddings = self.segment_embedding(token_type_ids)\n",
    "            embeddings = embeddings + segment_embeddings\n",
    "        \n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "# Example usage\n",
    "class BERTConfig:\n",
    "    def __init__(self):\n",
    "        self.vocab_size = 30522  # Example vocabulary size\n",
    "        self.hidden_size = 768\n",
    "        self.max_position_embeddings = 512\n",
    "        self.type_vocab_size = 2  # Two token types (0 and 1)\n",
    "        self.layer_norm_eps = 1e-12\n",
    "        self.hidden_dropout_prob = 0.1\n",
    "\n",
    "config = BERTConfig()\n",
    "bert_embeddings = BertEmbeddings(config)\n",
    "\n",
    "input_ids = torch.tensor([[101, 2058, 2022, 102], [101, 2003, 2016, 102]], dtype=torch.long)\n",
    "token_type_ids = torch.tensor([[0, 0, 0, 0], [0, 1, 1, 0]], dtype=torch.long)\n",
    "\n",
    "embeddings = bert_embeddings(input_ids, token_type_ids)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embed = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concatenate_with_padding_and_mask() missing 3 required positional arguments: 'tensor2', 'mask1', and 'mask2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tk_type_ids \u001b[39m=\u001b[39m concatenate_with_padding_and_mask(input_ids)\n\u001b[0;32m      2\u001b[0m tk_type_ids \u001b[39m=\u001b[39m create_attention_mask(tk_type_ids)\n\u001b[0;32m      3\u001b[0m tk_type_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtk_type_embedding(tk_type_ids)\n",
      "\u001b[1;31mTypeError\u001b[0m: concatenate_with_padding_and_mask() missing 3 required positional arguments: 'tensor2', 'mask1', and 'mask2'"
     ]
    }
   ],
   "source": [
    "tk_type_ids = concatenate_with_padding_and_mask(input_ids)\n",
    "tk_type_ids = create_attention_mask(tk_type_ids)\n",
    "tk_type_embeds = self.tk_type_embedding(tk_type_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
