{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a56b268-810d-49ab-87d5-c5090cf7cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_multitask_data\n",
    "import bert\n",
    "from config import PretrainedConfig\n",
    "import torch\n",
    "from datasets import SentencePairDataset\n",
    "from tokenizer import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba511a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This library gives a better idea of how to compute the hidden states\n",
    "# https://github.com/codertimo\n",
    "# https://pypi.org/project/bert-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb00015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install with pip install bert-pytorch\n",
    "import bert_pytorch.model.embedding.bert as bert_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f30c7b-5bae-473c-adc1-d1d7b9b99c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8544 train examples from data/ids-sst-train.csv\n",
      "Loaded 141498 train examples from data/quora-train.csv\n",
      "Loaded 6040 train examples from data/sts-train.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"the rock is destined to be the 21st century 's new `` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\",\n",
       " 3,\n",
       " '32a4f146782cbde1b7fa65799')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load project's datasets\n",
    "sentiment_data, num_labels, paraphrased_data, similarity_data = load_multitask_data(\"data/ids-sst-train.csv\", \"data/quora-train.csv\", \n",
    "                    \"data/sts-train.csv\")\n",
    "#Show example \n",
    "sentiment_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0edd4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0efc78-e290-42cc-855f-f25a76ee90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initialization parameters to validate the methods we create\n",
    "class BertConfig(PretrainedConfig):\n",
    "  model_type = \"bert\"\n",
    "\n",
    "  def __init__(\n",
    "    self,\n",
    "    vocab_size=30522,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    initializer_range=0.02,\n",
    "    layer_norm_eps=1e-12,\n",
    "    pad_token_id=0,\n",
    "    gradient_checkpointing=False,\n",
    "    position_embedding_type=\"absolute\",\n",
    "    use_cache=True,\n",
    "    name_or_path = \"checkpoint\",\n",
    "    **kwargs\n",
    "  ):\n",
    "    super().__init__(pad_token_id=pad_token_id, **kwargs)\n",
    "\n",
    "    self.vocab_size = vocab_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_hidden_layers = num_hidden_layers\n",
    "    self.num_attention_heads = num_attention_heads\n",
    "    self.hidden_act = hidden_act\n",
    "    self.intermediate_size = intermediate_size\n",
    "    self.hidden_dropout_prob = hidden_dropout_prob\n",
    "    self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "    self.max_position_embeddings = max_position_embeddings\n",
    "    self.type_vocab_size = type_vocab_size\n",
    "    self.initializer_range = initializer_range\n",
    "    self.layer_norm_eps = layer_norm_eps\n",
    "    self.gradient_checkpointing = gradient_checkpointing\n",
    "    self.position_embedding_type = position_embedding_type\n",
    "    self.use_cache = use_cache\n",
    "    self.name_or_path = name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b59d73a-4959-42c0-a543-098055647857",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1f0b6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(importlib.import_module(\"bert\"))\n",
    "\n",
    "bert_mod = bert.BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17c883da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and passing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "edf0a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_length = 15\n",
    "\n",
    "dummy_data = [\"the rock is destined to be the 21st century 's new `` conan \"]\n",
    "dummy_data = dummy_data*128\n",
    "#Still have not included CLS token\n",
    "tokenized_dummy_data= []\n",
    "for sequence in dummy_data:\n",
    "    x = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sequence))\n",
    "    x = x + [0] * (padded_length - len(x)) \n",
    "    tokenized_dummy_data.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ceff2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_tensor =  torch.LongTensor(tokenized_dummy_data)\n",
    "dummy_tensor_attention_mask = (dummy_tensor != 0).to(torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6cba6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = bert_mod.embed(dummy_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "094d9c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 15, 768])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "59f1cf6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bert_mod\u001b[39m.\u001b[39;49mencode(hidden_states,dummy_tensor_attention_mask)\n",
      "File \u001b[1;32mc:\\Users\\sago\\Documents\\GitHub\\word-alliance\\bert.py:246\u001b[0m, in \u001b[0;36mBertModel.encode\u001b[1;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39m# pass the hidden states through the encoder layers\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[39mfor\u001b[39;00m i, layer_module \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert_layers):\n\u001b[0;32m    245\u001b[0m   \u001b[39m# feed the encoding from the last bert_layer to the next\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m   hidden_states \u001b[39m=\u001b[39m layer_module(hidden_states, extended_attention_mask)\n\u001b[0;32m    248\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dnlp\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\sago\\Documents\\GitHub\\word-alliance\\bert.py:162\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[39mhidden_states: either from the embedding layer (first bert layer) or from the previous bert layer\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mas shown in the left of Figure 1 of https://arxiv.org/pdf/1706.03762.pdf \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m4. a add-norm that takes the input and output of the feed forward layer\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39m### TODO\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m self_attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attention\u001b[39m.\u001b[39;49mforward(hidden_states,attention_mask)\n\u001b[0;32m    163\u001b[0m normalized_attention_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_norm(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mhidden_states, output\u001b[39m=\u001b[39mself_attention_output , \n\u001b[0;32m    164\u001b[0m               dense_layer\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_dense, dropout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_dropout, ln_layer\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_layer_norm)\n\u001b[0;32m    166\u001b[0m ffn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterm_dense(normalized_attention_layer)\n",
      "File \u001b[1;32mc:\\Users\\sago\\Documents\\GitHub\\word-alliance\\bert.py:101\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m     99\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery)\n\u001b[0;32m    100\u001b[0m \u001b[39m# calculate the multi-head attention \u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m attn_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(key_layer, query_layer, value_layer, attention_mask)\n\u001b[0;32m    102\u001b[0m \u001b[39mreturn\u001b[39;00m attn_value\n",
      "File \u001b[1;32mc:\\Users\\sago\\Documents\\GitHub\\word-alliance\\bert.py:63\u001b[0m, in \u001b[0;36mBertSelfAttention.attention\u001b[1;34m(self, key, query, value, attention_mask)\u001b[0m\n\u001b[0;32m     61\u001b[0m dk \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]\n\u001b[0;32m     62\u001b[0m seq_len \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n\u001b[1;32m---> 63\u001b[0m repeated_attention_mask \u001b[39m=\u001b[39m attention_mask\u001b[39m.\u001b[39;49mrepeat(seq_len,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[39m# Initialize an empty list to store the result\u001b[39;00m\n\u001b[0;32m     65\u001b[0m result_list \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "bert_mod.encode(hidden_states,dummy_tensor_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0158e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
