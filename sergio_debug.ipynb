{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a56b268-810d-49ab-87d5-c5090cf7cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_multitask_data\n",
    "import bert\n",
    "from config import PretrainedConfig\n",
    "import torch\n",
    "from datasets import SentencePairDataset\n",
    "from tokenizer import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba511a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This library gives a better idea of how to compute the hidden states\n",
    "# https://github.com/codertimo\n",
    "# https://pypi.org/project/bert-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb00015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install with pip install bert-pytorch\n",
    "import bert_pytorch.model.embedding.bert as bert_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f30c7b-5bae-473c-adc1-d1d7b9b99c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8544 train examples from data/ids-sst-train.csv\n",
      "Loaded 141498 train examples from data/quora-train.csv\n",
      "Loaded 6040 train examples from data/sts-train.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"the rock is destined to be the 21st century 's new `` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\",\n",
       " 3,\n",
       " '32a4f146782cbde1b7fa65799')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load project's datasets\n",
    "sentiment_data, num_labels, paraphrased_data, similarity_data = load_multitask_data(\"data/ids-sst-train.csv\", \"data/quora-train.csv\", \n",
    "                    \"data/sts-train.csv\")\n",
    "#Show example \n",
    "sentiment_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0edd4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0efc78-e290-42cc-855f-f25a76ee90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initialization parameters to validate the methods we create\n",
    "class BertConfig(PretrainedConfig):\n",
    "  model_type = \"bert\"\n",
    "\n",
    "  def __init__(\n",
    "    self,\n",
    "    vocab_size=30522,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    initializer_range=0.02,\n",
    "    layer_norm_eps=1e-12,\n",
    "    pad_token_id=0,\n",
    "    gradient_checkpointing=False,\n",
    "    position_embedding_type=\"absolute\",\n",
    "    use_cache=True,\n",
    "    name_or_path = \"checkpoint\",\n",
    "    **kwargs\n",
    "  ):\n",
    "    super().__init__(pad_token_id=pad_token_id, **kwargs)\n",
    "\n",
    "    self.vocab_size = vocab_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_hidden_layers = num_hidden_layers\n",
    "    self.num_attention_heads = num_attention_heads\n",
    "    self.hidden_act = hidden_act\n",
    "    self.intermediate_size = intermediate_size\n",
    "    self.hidden_dropout_prob = hidden_dropout_prob\n",
    "    self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "    self.max_position_embeddings = max_position_embeddings\n",
    "    self.type_vocab_size = type_vocab_size\n",
    "    self.initializer_range = initializer_range\n",
    "    self.layer_norm_eps = layer_norm_eps\n",
    "    self.gradient_checkpointing = gradient_checkpointing\n",
    "    self.position_embedding_type = position_embedding_type\n",
    "    self.use_cache = use_cache\n",
    "    self.name_or_path = name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b59d73a-4959-42c0-a543-098055647857",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f0b6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(importlib.import_module(\"bert\"))\n",
    "\n",
    "bert_mod = bert.BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c883da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and passing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35bb1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_length = 15\n",
    "\n",
    "dummy_data = [\"the rock is destined to be the 21st century 's new `` conan \"]\n",
    "dummy_data = dummy_data*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4406dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = tokenizer(dummy_data, return_tensors='pt', padding='max_length', truncation=True,max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbbe2691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n"
     ]
    }
   ],
   "source": [
    "result_dict = bert_mod.forward(tokenized_data['input_ids'],tokenized_data['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1720cbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d46db4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50, 768])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "592f4280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 768])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['pooler_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59f1cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n",
      "hidden state from key layer size torch.Size([128, 50, 768])\n",
      "all head size 768\n",
      "concatenated tensor shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 768])\n",
      "input shape torch.Size([128, 50, 768])\n",
      "output shape torch.Size([128, 50, 3072])\n",
      "normalized_score_layer shape torch.Size([128, 50, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.4397, -0.2588,  0.6161,  ..., -2.2646,  0.6325,  0.6096],\n",
       "         [-0.2055, -1.0703,  0.4219,  ..., -0.4757, -0.0072,  0.0887],\n",
       "         [-0.4720,  0.0000,  0.1476,  ..., -0.0000,  3.2542, -0.8519],\n",
       "         ...,\n",
       "         [ 0.0682, -0.5010,  0.3616,  ..., -0.2935,  0.0000, -0.5955],\n",
       "         [ 0.0877,  0.3808, -3.2701,  ..., -0.0000, -0.2870, -0.0835],\n",
       "         [ 0.1736, -0.0000, -0.0000,  ..., -0.0000, -0.0076, -0.7290]],\n",
       "\n",
       "        [[ 1.4783, -0.5213,  0.5138,  ...,  0.4407,  0.0385,  0.3364],\n",
       "         [-0.2955, -1.7612,  0.1537,  ...,  0.5004,  0.4838, -3.4897],\n",
       "         [-0.0482, -1.6392, -0.3932,  ...,  0.7169,  1.7805,  0.3056],\n",
       "         ...,\n",
       "         [-0.3663, -0.0000,  0.0000,  ..., -1.2152, -0.6961,  0.5336],\n",
       "         [ 0.4940, -0.0000, -0.0615,  ..., -0.0000,  1.6459,  1.1692],\n",
       "         [ 1.3144,  1.3468, -0.0000,  ..., -1.7047,  1.5514, -0.0000]],\n",
       "\n",
       "        [[ 0.5243, -1.3725,  1.3530,  ...,  0.4718,  0.2918, -0.5091],\n",
       "         [ 0.1038, -0.8666,  0.2350,  ...,  1.2937, -0.3950,  0.5130],\n",
       "         [ 0.0743, -0.1101,  1.3484,  ...,  1.3180,  0.0000,  0.0130],\n",
       "         ...,\n",
       "         [ 0.8405, -0.2725, -0.0000,  ..., -0.2866,  1.9355,  0.8966],\n",
       "         [ 0.7509, -0.7594,  0.6524,  ...,  0.1268,  3.5939, -0.0698],\n",
       "         [ 0.1822, -0.0858, -0.3565,  ...,  0.6862,  0.2465, -1.9767]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.8069, -1.3633,  0.5518,  ...,  3.6899,  1.0488, -0.2600],\n",
       "         [ 0.6485, -0.3659,  0.1835,  ...,  0.0000,  0.6283,  0.3158],\n",
       "         [ 0.0000, -1.9790,  0.1024,  ..., -0.3290,  0.4416,  0.0860],\n",
       "         ...,\n",
       "         [ 0.4372, -4.9241, -0.1214,  ...,  0.5433, -0.2761,  0.4783],\n",
       "         [ 0.2161, -1.5690,  0.3951,  ..., -1.4388,  0.1032, -0.3795],\n",
       "         [ 0.1796, -0.4313, -0.4856,  ...,  1.9001, -0.7929, -2.0546]],\n",
       "\n",
       "        [[ 0.1483, -0.1400,  0.0926,  ...,  0.3975,  1.3034,  0.1649],\n",
       "         [ 0.0000, -0.1706, -0.0000,  ...,  1.1502,  0.9179,  0.4772],\n",
       "         [ 0.0000, -1.8130, -0.0000,  ...,  0.0000,  0.0000, -2.7503],\n",
       "         ...,\n",
       "         [-0.4663, -0.0681,  0.7675,  ...,  2.0042, -0.4236, -0.9137],\n",
       "         [-0.3399,  0.4579,  0.2061,  ..., -2.7042, -0.1035,  0.2078],\n",
       "         [ 0.9193, -1.2845, -0.1165,  ...,  0.5103,  1.2439,  0.4175]],\n",
       "\n",
       "        [[ 0.3608,  0.5071,  0.0000,  ...,  1.7644,  0.8075, -0.8769],\n",
       "         [ 0.1436, -0.5288, -1.7181,  ...,  0.2829, -0.1601, -0.0000],\n",
       "         [ 0.0000, -0.1029,  0.7334,  ..., -1.1782,  1.3996,  0.0526],\n",
       "         ...,\n",
       "         [-0.2332, -4.2325, -0.3906,  ...,  0.7888, -1.9619,  0.5193],\n",
       "         [ 2.1437,  0.0250,  1.4111,  ...,  0.4160,  0.3125,  0.4524],\n",
       "         [ 0.1451, -0.0000, -4.0395,  ..., -1.0023,  1.2543,  0.3344]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_mod.encode(hidden_states,tokenized_data['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0158e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
